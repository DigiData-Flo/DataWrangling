{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Data Wrangling Project\n",
    "\n",
    "## We Rate Dogs - Twitter\n",
    "\n",
    "In this Udacity project I showed how programmatic data wrangling works.\n",
    "\n",
    "## Data Sets\n",
    "The starting point for the data was a file that could be downloaded as a Twitter archive. In this file, each line corresponded to a tweet. The most important column was above all the Tweet ID. With the Tweet IDs it is possible to download the complete Tweet dataset via the Twitter API. That was when the real data wrangling began.\n",
    "## Data Gathering\n",
    "Die heruntergeladenen Daten im json Format wurden zun√§chst in eine Text Datei gespeichert und von dort in einen Panda Dataframe geladen. Praktischer Weise kann Panda ein json Objekt direkt in einen Dataframe speichern.\n",
    "The Twitter archive was directly available for download. The prediction file had to be downloaded via the Python requests module. The original tweet dataset had to be obtained via the Twitter API. This was problematic in that I had some problems generating the API keys and tokens, as well as the associated secrets. Downloading the tweets itself wasn't a big problem, thanks to the Python library tweepy.\n",
    "The downloaded data in json format was first saved in a text file and from there loaded into a Panda data frame. In a practical way, Panda can save a json object directly into a data frame.\n",
    "\n",
    "\n",
    "## Data Assessment\n",
    "After I had loaded all the data, the assessment of the data began. I found both poor quality data and untidiness data. I did the assessment programmatically with python and pandas and also some visual inspections for better understanding of the data.\n",
    "To do this, I first looked at each data record individually to find out which data is hidden in the columns, how you can recognize a retweet, which data types are useful for the columns, and how you could fix any problems.\n",
    "The data assessment is perhaps one of the most complex processes of data wrangling, but the more thorough the assessment, the easier the cleaning process is afterwards.\n",
    "\n",
    "\n",
    "## Data Cleaning\n",
    "After the assessment, I cleaned up the data with python and pandas. Together with the assessment, this was an iterative process, since when cleaning the data, new issues occurred or something did not work as planned.\n",
    "Really Crazy was the rating extraction. Should I clean only numerators below 10 and denominators above 10? But there is no rule, that the numinator must above and the denominator must be equal to 10. Therefor I decide to recreate all rating values by extracting by myself, with manual rework for more than one found ratin pattern.\n",
    "The twitter archiv itself was really messy data. Specially regarding missing data, and rating values.\n",
    "\n",
    "\n",
    "## Analysis Data and Finding Insights\n",
    "And here are my insights. There is much more to analyse but this is not scope of the project.\n",
    "\n",
    "![scatter](images/insight3.png)\n",
    "#### There is a nice correlation between the retweet count and the favorite counts\n",
    "\n",
    "`Note:` I talk here about a correlation, not about causing effects.\n",
    "\n",
    "![favorites](images/most_favorites_breeds.png)\n",
    "#### The mean most favorite counts goes to the breed  Bedlington terrier\n",
    "![likes](images/insight1.png)\n",
    "#### The highest numerator mean goes to the clumber breed. It is not really a mean, there is only one clumber in the dataset.\n",
    "![retweets](images/insight2.png)\n",
    "#### The lowest numerator mean goes to the  Japanese Spaniel breed.\n",
    "![retweets](images/The_undertaker.png)\n",
    "#### And here I present a picture from Japanese Spaniel. I call him The Undertaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
